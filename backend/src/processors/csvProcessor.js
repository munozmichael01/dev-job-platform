const { pool, sql } = require("../db/db")
const csv = require('csv-parser')
const fs = require('fs')
const path = require('path')

class CSVProcessor {
  constructor(connection, filePath = null) {
    this.connection = connection
    this.filePath = filePath
    console.log("üîß CSVProcessor initialized for connection:", connection.id)
  }

  // ‚úÖ M√âTODO PARA DETECTAR CAMPOS DEL CSV
  async detectFields(filePath = null) {
    try {
      console.log("üîç Detecting fields from CSV...")
      
      const csvFilePath = filePath || this.filePath
      if (!csvFilePath || !fs.existsSync(csvFilePath)) {
        throw new Error("CSV file path not provided or file doesn't exist")
      }

      return new Promise((resolve, reject) => {
        const fields = []
        let isFirstRow = true
        let sampleData = null

        fs.createReadStream(csvFilePath)
          .pipe(csv())
          .on('data', (row) => {
            if (isFirstRow) {
              // Obtener muestra de datos de la primera fila
              sampleData = row
              
              // Generar descripci√≥n de campos
              Object.keys(row).forEach(fieldName => {
                const value = row[fieldName] || ""
                const stringValue = String(value).trim()

                fields.push({
                  name: fieldName,
                  type: this.detectFieldType(fieldName, stringValue),
                  sample: stringValue.length > 100 ? stringValue.substring(0, 100) + "..." : stringValue,
                  required: false,
                  description: this.generateFieldDescription(fieldName, stringValue),
                })
              })
              
              isFirstRow = false
            }
          })
          .on('end', () => {
            console.log(`‚úÖ Detected ${fields.length} fields from CSV`)
            resolve(fields)
          })
          .on('error', reject)
      })
    } catch (error) {
      console.error("‚ùå Error detecting fields:", error)
      throw error
    }
  }

  // ‚úÖ DETECTAR TIPO DE CAMPO
  detectFieldType(fieldName, value) {
    const name = fieldName.toLowerCase()

    // URLs
    if (name.includes("url") || name.includes("link") || (value && value.startsWith("http"))) {
      return "url"
    }

    // Fechas
    if (name.includes("date") || name.includes("publication") || name.includes("created") || name.includes("fecha")) {
      return "date"
    }

    // N√∫meros
    if (name.includes("id") || name.includes("count") || name.includes("number") || name.includes("salary") || name.includes("precio") || name.includes("salario")) {
      return "number"
    }

    // Por defecto string
    return "string"
  }

  // ‚úÖ GENERAR DESCRIPCI√ìN DEL CAMPO
  generateFieldDescription(fieldName, value) {
    const name = fieldName.toLowerCase()

    const descriptions = {
      id: "ID √∫nico de la oferta",
      title: "T√≠tulo de la oferta",
      jobtitle: "T√≠tulo del puesto de trabajo",
      company: "Nombre de la empresa",
      content: "Descripci√≥n completa",
      description: "Descripci√≥n del puesto",
      category: "Categor√≠a o sector",
      city: "Ciudad",
      location: "Ubicaci√≥n",
      url: "URL externa",
      url_apply: "URL de aplicaci√≥n",
      publication: "Fecha de publicaci√≥n",
      salary: "Salario",
      jobtype: "Tipo de trabajo",
      region: "Regi√≥n",
      postcode: "C√≥digo postal",
      address: "Direcci√≥n",
      budget: "Presupuesto",
      goal: "Objetivo de aplicaciones",
      vacancies: "N√∫mero de vacantes",
      pais: "Pa√≠s",
      country: "Pa√≠s",
      subcategory: "Subcategor√≠a",
      companyid: "ID de empresa",
      idpais: "ID del pa√≠s",
      idregion: "ID de regi√≥n",
      idcity: "ID de ciudad",
      num_vacancies: "N√∫mero de vacantes",
      company_logo_url: "Logo de la empresa",
      empresa: "Nombre de la empresa",
      puesto: "Puesto de trabajo",
      localidad: "Localidad",
      provincia: "Provincia",
      fecha: "Fecha",
      salario: "Salario",
      tipo: "Tipo de contrato"
    }

    return descriptions[name] || `Campo: ${fieldName}`
  }

  // ‚úÖ M√âTODO PARA PROBAR LA CONEXI√ìN (para archivos CSV subidos)
  async test(filePath = null) {
    try {
      console.log("üß™ Testing CSV file...")
      
      const csvFilePath = filePath || this.filePath
      if (!csvFilePath || !fs.existsSync(csvFilePath)) {
        throw new Error("CSV file path not provided or file doesn't exist")
      }

      // Leer las primeras 5 filas para validaci√≥n
      return new Promise((resolve, reject) => {
        const sampleData = []
        let rowCount = 0

        fs.createReadStream(csvFilePath)
          .pipe(csv())
          .on('data', (row) => {
            if (rowCount < 5) {
              sampleData.push(row)
              rowCount++
            }
          })
          .on('end', () => {
            console.log("‚úÖ CSV file test successful")
            resolve({
              success: true,
              message: "Archivo CSV v√°lido",
              sampleData: sampleData,
              totalRows: rowCount
            })
          })
          .on('error', (error) => {
            reject({
              success: false,
              message: error.message,
            })
          })
      })
    } catch (error) {
      console.error("‚ùå CSV file test failed:", error)
      return {
        success: false,
        message: error.message,
      }
    }
  }

  // ‚úÖ CARGAR MAPPINGS
  async loadMappings() {
    try {
      console.log(`üìã Loading mappings for connection ${this.connection.id}...`)
      const result = await pool
        .request()
        .input("ConnectionId", sql.Int, this.connection.id)
        .query("SELECT * FROM ClientFieldMappings WHERE ConnectionId = @ConnectionId")

      console.log(`üìã Loaded ${result.recordset.length} mappings`)
      return result.recordset
    } catch (error) {
      console.error("‚ùå Error loading mappings:", error)
      return []
    }
  }

  async process(filePath = null, batchSize = 100) {
    try {
      console.log("üîÑ Starting CSV processing...")
      console.log(`üîç CSV FILE PATH: ${filePath || this.filePath}`)

      const csvFilePath = filePath || this.filePath
      if (!csvFilePath || !fs.existsSync(csvFilePath)) {
        throw new Error("CSV file path not provided or file doesn't exist")
      }

      console.log(`üîç File exists: ${fs.existsSync(csvFilePath)}`)
      console.log(`üîç File size: ${fs.statSync(csvFilePath).size} bytes`)

      // 1. Cargar mappings
      const mappings = await this.loadMappings()
      console.log(`üîç MAPPINGS LOADED: ${mappings.length} mappings found`)
      if (mappings.length > 0) {
        console.log(`üîç MAPPINGS SAMPLE:`, mappings.slice(0, 3))
      }

      if (mappings.length === 0) {
        console.log("‚ö†Ô∏è No mappings found, using default mapping")
      }

      // 2. Procesar CSV
      console.log("üîÑ Starting CSV parsing...")
      const offers = await this.parseCSV(csvFilePath)
      console.log(`üìä Found ${offers.length} offers in CSV`)
      
      // Log first offer structure for debugging
      if (offers.length > 0) {
        console.log(`üîç RAW CSV FIRST OFFER:`, JSON.stringify(offers[0], null, 2))
        console.log(`üîç First offer structure:`, Object.keys(offers[0]))
        console.log(`üîç First offer field count:`, Object.keys(offers[0]).length)
      } else {
        console.log("‚ùå NO OFFERS PARSED FROM CSV!")
        return { imported: 0, errors: 1, failedOffers: [{ reason: "No data found in CSV file" }] }
      }

      // 3. Transformar seg√∫n mappings
      console.log("üîÑ Starting transformation to standard format...")
      const transformedOffers = offers.map((offer, index) => {
        console.log(`üîÑ Transforming offer ${index + 1}/${offers.length}...`)
        const transformed = this.mapToStandardFormat(offer, mappings)
        if (index === 0) {
          console.log(`üîç TRANSFORMED FIRST OFFER:`, JSON.stringify(transformed, null, 2))
        }
        return transformed
      })

      console.log(`üîç TRANSFORMED ${transformedOffers.length} offers`)

      // 4. Procesar por lotes
      const batches = this.splitIntoBatches(transformedOffers, batchSize)
      console.log(`üîÑ Created ${batches.length} batches of max ${batchSize} offers each`)
      
      let totalProcessed = 0
      let totalFailed = 0
      const failedOffers = []

      for (let i = 0; i < batches.length; i++) {
        console.log(`üîÑ Processing batch ${i + 1}/${batches.length} (${batches[i].length} offers)...`)
        const batchResult = await this.processBatch(batches[i])
        console.log(`üìä Batch ${i + 1} results: ${batchResult.processed} processed, ${batchResult.failed.length} failed`)
        totalProcessed += batchResult.processed
        totalFailed += batchResult.failed.length
        failedOffers.push(...batchResult.failed)
        
        // Log first few failed offers for debugging
        if (batchResult.failed.length > 0) {
          console.log(`‚ùå First failed offer in batch ${i + 1}:`, batchResult.failed[0])
        }
      }

      // 5. Archivar ofertas antiguas
      console.log("üîÑ Archiving old offers...")
      await this.archiveOldOffers(transformedOffers.map((o) => o.ExternalId))

      console.log(`‚úÖ Processing completed: ${totalProcessed} processed, ${totalFailed} failed`)

      // 6. Generar mapeo autom√°tico SIEMPRE que se procesen ofertas exitosamente
      if (totalProcessed > 0) {
        console.log("üîÑ Generating/updating automatic mapping...")
        console.log("üîç MAPPING DEBUG: Sample offer fields:", Object.keys(offers[0]))
        console.log("üîç MAPPING DEBUG: First 3 field samples:", Object.entries(offers[0]).slice(0, 3))
        await this.generateAutomaticMapping(offers[0])
      } else {
        console.log("‚ö†Ô∏è No offers processed successfully - skipping automatic mapping generation")
        console.log("üîç FAILED OFFERS SUMMARY:", failedOffers.slice(0, 5))
      }

      return {
        imported: totalProcessed,
        errors: totalFailed,
        failedOffers,
      }
    } catch (error) {
      console.error("‚ùå Error in CSV processing:", error)
      console.error("‚ùå Error stack:", error.stack)
      throw new Error(`Error processing CSV: ${error.message}`)
    }
  }

  async parseCSV(filePath) {
    console.log("üöÄ CLAUDE DEBUG: parseCSV FUNCTION CALLED WITH NEW CODE!")
    console.log(`üöÄ CLAUDE DEBUG: FilePath: ${filePath}`)
    return new Promise(async (resolve, reject) => {
      try {
        // ‚úÖ DETECTAR AUTOM√ÅTICAMENTE SI HAY HEADERS
        console.log("üöÄ CLAUDE DEBUG: About to detect headers...")
        const hasHeaders = await this.detectHeaders(filePath)
        console.log(`üöÄ CLAUDE DEBUG: Headers detected: ${hasHeaders}`)
        
        const offers = []
        let isFirstRow = true
        let headerRow = null
        
        // ‚úÖ CONFIGURAR CSV PARSER FLEXIBLE
        const csvOptions = {
          headers: false, // Manejar headers manualmente
          skipEmptyLines: true,
          quote: '"',
          escape: '"',
          raw: false,
          strictColumnHandling: false,
          maxRowBytes: 100000,
          skipLinesWithError: false
        }
        
        fs.createReadStream(filePath)
          .pipe(csv(csvOptions))
          .on('data', (row) => {
            try {
              if (isFirstRow && hasHeaders) {
                // Guardar headers y saltar esta fila
                headerRow = row
                isFirstRow = false
                console.log(`üìã Headers found:`, headerRow.slice(0, 10))
                return
              }
              
              isFirstRow = false
              
              // ‚úÖ CONVERTIR ARRAY A OBJETO
              const offerObject = {}
              
              if (hasHeaders && headerRow) {
                // ‚úÖ USAR HEADERS COMO NOMBRES DE CAMPO
                for (let i = 0; i < row.length; i++) {
                  let value = row[i] || ""
                  
                  // ‚úÖ LIMPIAR HTML EMBEBIDO Y CARACTERES ESPECIALES
                  if (typeof value === 'string') {
                    value = value
                      .replace(/&lt;/g, '<')
                      .replace(/&gt;/g, '>')
                      .replace(/&amp;/g, '&')
                      .replace(/&quot;/g, '"')
                      .replace(/&#39;/g, "'")
                      .replace(/&nbsp;/g, ' ')
                      .trim()
                  }
                  
                  const fieldName = headerRow[i] || `col_${i}`
                  offerObject[fieldName] = value
                  offerObject[`col_${i}`] = value // Tambi√©n mantener posici√≥n
                }
              } else {
                // ‚úÖ SIN HEADERS - USAR POSICIONES
                for (let i = 0; i < row.length; i++) {
                  let value = row[i] || ""
                  
                  if (typeof value === 'string') {
                    value = value
                      .replace(/&lt;/g, '<')
                      .replace(/&gt;/g, '>')
                      .replace(/&amp;/g, '&')
                      .replace(/&quot;/g, '"')
                      .replace(/&#39;/g, "'")
                      .replace(/&nbsp;/g, ' ')
                      .trim()
                  }
                  
                  offerObject[`col_${i}`] = value
                }
                
                // Mapeo espec√≠fico para CSV sin headers
                offerObject.id = offerObject.col_0
                offerObject.title = offerObject.col_24
                offerObject.location = offerObject.col_26
              }
              
              offers.push(offerObject)
            } catch (rowError) {
              console.warn(`‚ö†Ô∏è Error processing CSV row: ${rowError.message}`)
            }
          })
          .on('end', () => {
            console.log(`‚úÖ CSV parsed successfully, ${offers.length} rows`)
            if (offers.length > 0) {
              console.log(`‚úÖ First offer structure:`, Object.keys(offers[0]).slice(0, 10))
              console.log(`‚úÖ Sample values:`, {
                firstKey: Object.keys(offers[0])[0],
                firstValue: offers[0][Object.keys(offers[0])[0]],
                hasId: !!offers[0].id,
                hasTitle: !!offers[0].title
              })
            }
            resolve(offers)
          })
          .on('error', reject)
      } catch (error) {
        reject(error)
      }
    })
  }

  // ‚úÖ DETECTAR SI LA PRIMERA FILA CONTIENE HEADERS
  async detectHeaders(filePath) {
    return new Promise((resolve) => {
      let firstRow = null
      
      fs.createReadStream(filePath)
        .pipe(csv({ headers: false }))
        .on('data', (row) => {
          if (!firstRow) {
            firstRow = row
            
            // ‚úÖ HEUR√çSTICAS PARA DETECTAR HEADERS
            let headerScore = 0
            let totalFields = Math.min(row.length, 10) // Analizar primeros 10 campos
            
            for (let i = 0; i < totalFields; i++) {
              const value = String(row[i] || "").trim()
              
              if (value) {
                // Headers t√≠picos: contienen texto, no solo n√∫meros
                if (isNaN(Number(value))) headerScore++
                
                // Headers comunes
                if (/^(id|title|name|company|city|location|url|date|publication|salary|description|content)$/i.test(value)) {
                  headerScore += 2
                }
                
                // Headers en espa√±ol
                if (/^(titulo|empresa|ciudad|ubicacion|fecha|salario|descripcion|contenido|puesto)$/i.test(value)) {
                  headerScore += 2
                }
              }
            }
            
            // Si m√°s del 50% parecen headers, asumir que tiene headers
            const hasHeaders = headerScore > (totalFields * 0.5)
            console.log(`üîç Header detection - Score: ${headerScore}/${totalFields}, Has headers: ${hasHeaders}`)
            resolve(hasHeaders)
          }
        })
        .on('error', () => resolve(false))
    })
  }

  splitIntoBatches(array, batchSize) {
    const batches = []
    for (let i = 0; i < array.length; i += batchSize) {
      batches.push(array.slice(i, i + batchSize))
    }
    return batches
  }

  async processBatch(offers) {
    const results = {
      processed: 0,
      failed: [],
    }

    console.log(`üîÑ Starting processBatch with ${offers.length} offers`)
    
    for (let i = 0; i < offers.length; i++) {
      const offer = offers[i]
      console.log(`üîÑ Processing offer ${i + 1}/${offers.length}: ${offer.ExternalId}`)
      
      try {
        console.log(`üîç About to save offer with data:`, {
          ExternalId: offer.ExternalId,
          Title: offer.Title,
          CompanyName: offer.CompanyName,
          ConnectionId: offer.ConnectionId
        })
        
        await this.saveOffer(offer)
        console.log(`‚úÖ Successfully saved offer ${offer.ExternalId}`)
        results.processed++
      } catch (error) {
        console.error(`‚ùå Failed to save offer ${offer.ExternalId}:`, error.message)
        console.error(`‚ùå Full error:`, error)
        console.error(`‚ùå Offer data that failed:`, JSON.stringify(offer, null, 2))
        results.failed.push({
          id: offer.ExternalId,
          reason: error.message,
          fullError: error.toString()
        })
      }
    }

    console.log(`üìä processBatch completed: ${results.processed} processed, ${results.failed.length} failed`)
    return results
  }

  mapToStandardFormat(offer, mappings) {
    const standardOffer = {}

    if (mappings.length > 0) {
      // Usar mappings configurados
      for (const mapping of mappings) {
        try {
          let value
          if (mapping.SourceField === "content") {
            value = offer.content
          } else {
            value = this.getValueFromPath(offer, mapping.SourceField)
          }

          standardOffer[mapping.TargetField] = this.transformValue(
            value,
            mapping.TransformationType || "STRING",
            mapping.TransformationRule,
          )
        } catch (error) {
          standardOffer[mapping.TargetField] = null
        }
      }
    } else {
      // Mapeo autom√°tico por defecto - adaptado para CSV en espa√±ol
      standardOffer.ExternalId = String(offer.id || offer.ID || offer.Id || offer.codigo || offer.identifier || offer.externalId || Math.random().toString(36).substr(2, 9))
      standardOffer.Title = String(offer.title || offer.titulo || offer.puesto || offer.jobtitle || offer.job_title || "")
      standardOffer.JobTitle = String(offer.jobtitle || offer.puesto || offer.job_title || offer.title || offer.titulo || "")
      standardOffer.Description = String(offer.content || offer.description || offer.descripcion || offer.job_description || "")
      standardOffer.CompanyName = String(offer.company || offer.empresa || offer.company_name || "")
      standardOffer.Sector = String(offer.category || offer.categoria || offer.sector || "")
      standardOffer.Address = String(offer.address || offer.direccion || offer.location || offer.ubicacion || "")
      standardOffer.Country = String(offer.pais || offer.country || offer.pa√≠s || "Espa√±a")
      standardOffer.Region = String(offer.region || offer.provincia || offer.comunidad || "")
      standardOffer.City = String(offer.city || offer.ciudad || offer.localidad || offer.municipio || "")
      standardOffer.Postcode = String(offer.postcode || offer.codigo_postal || offer.cp || offer.postal_code || "")
      standardOffer.Vacancies = Number(offer.vacancies || offer.vacantes || offer.num_vacancies || offer.numero_vacantes || 1)
      standardOffer.JobType = String(offer.jobtype || offer.tipo_contrato || offer.job_type || offer.tipo || "")
      standardOffer.ExternalUrl = String(offer.url || offer.enlace || offer.external_url || "")
      standardOffer.ApplicationUrl = String(offer.url_apply || offer.url_aplicacion || offer.application_url || offer.apply_url || "")
      standardOffer.PublicationDate = this.parseDate(offer.publication || offer.fecha || offer.publication_date || offer.date || offer.fecha_publicacion)
      standardOffer.SalaryMin = Number(offer.salary_min || offer.salario_min || offer.salaryMin || 0) || null
      standardOffer.SalaryMax = Number(offer.salary_max || offer.salario_max || offer.salaryMax || 0) || null
      standardOffer.CountryId = Number(offer.idpais || offer.countryId || offer.id_pais || null) || null
      standardOffer.RegionId = Number(offer.idregion || offer.regionId || offer.id_region || null) || null
      standardOffer.CityId = Number(offer.idcity || offer.cityId || offer.id_ciudad || null) || null
      standardOffer.Latitude = Number(offer.latitude || offer.lat || offer.latitud || null) || null
      standardOffer.Longitude = Number(offer.longitude || offer.lng || offer.longitud || null) || null
    }

    // Campos obligatorios
    standardOffer.ConnectionId = this.connection.id
    standardOffer.Source = "CSV"
    standardOffer.CreatedAt = new Date()
    standardOffer.StatusId = 1
    standardOffer.BudgetSpent = 0
    standardOffer.ApplicationsReceived = 0

    // ‚úÖ VALIDACI√ìN MEJORADA - Asegurar campos requeridos no vac√≠os
    if (!standardOffer.ExternalId || standardOffer.ExternalId.trim() === '') {
      standardOffer.ExternalId = `csv_${Date.now()}_${Math.random().toString(36).substr(2, 5)}`
    }
    if (!standardOffer.Title || standardOffer.Title.trim() === '') {
      standardOffer.Title = 'Oferta de trabajo'
    }
    if (!standardOffer.CompanyName || standardOffer.CompanyName.trim() === '') {
      standardOffer.CompanyName = 'Empresa'
    }
    if (!standardOffer.PublicationDate || isNaN(new Date(standardOffer.PublicationDate))) {
      standardOffer.PublicationDate = new Date()
    }

    // Valores por defecto
    if (!standardOffer.Budget) standardOffer.Budget = 10
    if (!standardOffer.ApplicationsGoal) standardOffer.ApplicationsGoal = 50
    if (!standardOffer.Vacancies) standardOffer.Vacancies = 1

    // Asegurar que ExternalId sea string
    if (standardOffer.ExternalId) {
      standardOffer.ExternalId = String(standardOffer.ExternalId)
    }

    return standardOffer
  }

  getValueFromPath(obj, path) {
    return path.split(".").reduce((current, part) => current?.[part], obj)
  }

  transformValue(value, type, rule) {
    if (value === undefined || value === null) return null

    switch (type) {
      case "DATE":
        return this.parseDate(value)
      case "NUMBER":
        return Number(value) || null
      case "BOOLEAN":
        return Boolean(value)
      case "ARRAY":
        if (Array.isArray(value)) {
          return value[0] || null
        }
        return value || null
      case "STRING":
      default:
        return String(value || "")
    }
  }

  parseDate(dateStr) {
    if (!dateStr) return new Date()

    try {
      // Manejar diferentes formatos de fecha comunes en CSV
      const [datePart, timePart] = String(dateStr).split(" ")
      
      if (datePart && datePart.includes("/")) {
        const [day, month, year] = datePart.split("/")
        const time = timePart || "00:00:00"
        const formattedTime = time.split(":").length === 2 ? `${time}:00` : time

        const date = new Date(
          Number.parseInt(year),
          Number.parseInt(month) - 1,
          Number.parseInt(day),
          ...formattedTime.split(":").map(Number),
        )

        if (!isNaN(date.getTime())) {
          return date
        }
      }

      if (datePart && datePart.includes("-")) {
        const [year, month, day] = datePart.split("-")
        const time = timePart || "00:00:00"
        
        const date = new Date(
          Number.parseInt(year),
          Number.parseInt(month) - 1,
          Number.parseInt(day),
          ...time.split(":").map(Number),
        )

        if (!isNaN(date.getTime())) {
          return date
        }
      }

      const directParse = new Date(dateStr)
      if (!isNaN(directParse.getTime())) {
        return directParse
      }

      return new Date()
    } catch (error) {
      return new Date()
    }
  }

  async saveOffer(offer) {
    try {
      console.log(`üíæ Starting saveOffer for ${offer.ExternalId}`)
      console.log(`üíæ Preparing SQL parameters for offer:`, {
        ExternalId: offer.ExternalId,
        Title: offer.Title,
        CompanyName: offer.CompanyName,
        ConnectionId: offer.ConnectionId,
        PublicationDate: offer.PublicationDate
      })

      const result = await pool
        .request()
        .input("ExternalId", sql.NVarChar(255), String(offer.ExternalId))
        .input("Title", sql.NVarChar(255), offer.Title || "")
        .input("JobTitle", sql.NVarChar(255), offer.JobTitle || offer.Title || "")
        .input("Description", sql.NVarChar(sql.MAX), offer.Description)
        .input("CompanyName", sql.NVarChar(255), offer.CompanyName || "")
        .input("Sector", sql.NVarChar(255), offer.Sector || "")
        .input("Address", sql.NVarChar(255), offer.Address || "")
        .input("Country", sql.NVarChar(100), offer.Country || "")
        .input("CountryId", sql.Int, offer.CountryId || null)
        .input("Region", sql.NVarChar(100), offer.Region || "")
        .input("RegionId", sql.Int, offer.RegionId || null)
        .input("City", sql.NVarChar(100), offer.City || "")
        .input("CityId", sql.Int, offer.CityId || null)
        .input("Postcode", sql.NVarChar(20), offer.Postcode || "")
        .input("Latitude", sql.Decimal(9, 6), offer.Latitude || null)
        .input("Longitude", sql.Decimal(9, 6), offer.Longitude || null)
        .input("Vacancies", sql.Int, offer.Vacancies || 1)
        .input("SalaryMin", sql.Decimal(10, 2), offer.SalaryMin || 0)
        .input("SalaryMax", sql.Decimal(10, 2), offer.SalaryMax || 0)
        .input("JobType", sql.NVarChar(100), offer.JobType || "")
        .input("ExternalUrl", sql.NVarChar(500), offer.ExternalUrl || "")
        .input("ApplicationUrl", sql.NVarChar(500), offer.ApplicationUrl || "")
        .input("Budget", sql.Decimal(10, 2), offer.Budget || 10)
        .input("BudgetSpent", sql.Decimal(10, 2), offer.BudgetSpent || 0)
        .input("ApplicationsGoal", sql.Int, offer.ApplicationsGoal || 50)
        .input("ApplicationsReceived", sql.Int, offer.ApplicationsReceived || 0)
        .input("StatusId", sql.Int, offer.StatusId || 1)
        .input("ConnectionId", sql.Int, offer.ConnectionId)
        .input("Source", sql.NVarChar(10), offer.Source || "CSV")
        .input("PublicationDate", sql.DateTime, offer.PublicationDate || new Date())
        .input("CreatedAt", sql.DateTime, offer.CreatedAt || new Date())
        .query(`
          MERGE INTO JobOffers WITH (HOLDLOCK) AS Target
          USING (SELECT @ExternalId AS ExternalId, @ConnectionId AS ConnectionId) AS Source
          ON Target.ExternalId = Source.ExternalId AND Target.ConnectionId = Source.ConnectionId
          WHEN MATCHED THEN
            UPDATE SET 
              Title = @Title,
              JobTitle = @JobTitle,
              Description = @Description,
              CompanyName = @CompanyName,
              Sector = @Sector,
              Address = @Address,
              Country = @Country,
              CountryId = @CountryId,
              Region = @Region,
              RegionId = @RegionId,
              City = @City,
              CityId = @CityId,
              Postcode = @Postcode,
              Latitude = @Latitude,
              Longitude = @Longitude,
              Vacancies = @Vacancies,
              SalaryMin = @SalaryMin,
              SalaryMax = @SalaryMax,
              JobType = @JobType,
              ExternalUrl = @ExternalUrl,
              ApplicationUrl = @ApplicationUrl,
              Budget = @Budget,
              BudgetSpent = @BudgetSpent,
              ApplicationsGoal = @ApplicationsGoal,
              ApplicationsReceived = @ApplicationsReceived,
              StatusId = @StatusId,
              Source = @Source,
              PublicationDate = @PublicationDate
          WHEN NOT MATCHED THEN
            INSERT (
              ExternalId, Title, JobTitle, Description, CompanyName, Sector, Address,
              Country, CountryId, Region, RegionId, City, CityId, Postcode,
              Latitude, Longitude, Vacancies, SalaryMin, SalaryMax, JobType,
              ExternalUrl, ApplicationUrl, Budget, BudgetSpent, ApplicationsGoal,
              ApplicationsReceived, StatusId, ConnectionId, Source, PublicationDate, CreatedAt
            )
            VALUES (
              @ExternalId, @Title, @JobTitle, @Description, @CompanyName, @Sector, @Address,
              @Country, @CountryId, @Region, @RegionId, @City, @CityId, @Postcode,
              @Latitude, @Longitude, @Vacancies, @SalaryMin, @SalaryMax, @JobType,
              @ExternalUrl, @ApplicationUrl, @Budget, @BudgetSpent, @ApplicationsGoal,
              @ApplicationsReceived, @StatusId, @ConnectionId, @Source, @PublicationDate, @CreatedAt
            );
        `)
      
      console.log(`üíæ SQL query executed successfully for ${offer.ExternalId}`)
      console.log(`üíæ Query result:`, { rowsAffected: result.rowsAffected })
      
    } catch (error) {
      console.error(`üíæ SQL Error for offer ${offer.ExternalId}:`, error.message)
      console.error(`üíæ SQL Error details:`, error)
      throw new Error(`Error saving offer: ${error.message}`)
    }
  }

  async archiveOldOffers(activeExternalIds) {
    if (activeExternalIds.length === 0) return

    try {
      console.log(`üóÑÔ∏è Archiving old offers, keeping ${activeExternalIds.length} active...`)

      // Dividir en lotes de m√°ximo 2000 IDs para evitar el l√≠mite de SQL Server
      const batchSize = 2000
      const batches = []

      for (let i = 0; i < activeExternalIds.length; i += batchSize) {
        batches.push(activeExternalIds.slice(i, i + batchSize))
      }

      for (let i = 0; i < batches.length; i++) {
        const batch = batches[i]
        console.log(`üóÑÔ∏è Processing archive batch ${i + 1}/${batches.length} (${batch.length} IDs)...`)

        // Crear lista de par√°metros seguros
        const placeholders = batch.map((_, index) => `@id${index}`).join(",")
        const request = pool.request().input("ConnectionId", sql.Int, this.connection.id)

        // Agregar cada ID como par√°metro
        batch.forEach((id, index) => {
          request.input(`id${index}`, sql.NVarChar(255), String(id))
        })

        await request.query(`
          UPDATE JobOffers
          SET StatusId = 2
          WHERE ConnectionId = @ConnectionId
          AND Source = 'CSV'
          AND ExternalId NOT IN (${placeholders})
        `)
      }

      console.log("‚úÖ Old offers archived successfully")
    } catch (error) {
      console.error("‚ùå Error archiving old offers:", error.message)
      // No lanzar error para no interrumpir el proceso principal
    }
  }

  // ‚úÖ GENERAR MAPEO AUTOM√ÅTICO
  async generateAutomaticMapping(sampleOffer) {
    try {
      console.log("üöÄ CLAUDE DEBUG: generateAutomaticMapping CSV CALLED WITH NEW CODE!")
      console.log("üöÄ CLAUDE DEBUG: Sample offer keys:", Object.keys(sampleOffer))
      console.log("üîÑ Generating automatic field mappings...")
      console.log("üîç MAPPING DEBUG: generateAutomaticMapping called with fields:", Object.keys(sampleOffer))

      const mappings = []
      const offerFields = Object.keys(sampleOffer)

      // ‚úÖ MAPEO EST√ÅNDAR CORREGIDO - Incluir mapeos por posici√≥n de columna Y por nombre
      const standardMappings = {
        // Mapeos por posici√≥n de columna (para CSV sin headers)
        'col_0': 'apply_url',    // ID de la oferta -> campo temporal
        'col_24': 'title',       // T√≠tulo de la oferta
        'col_26': 'location',    // Ciudad/ubicaci√≥n
        'id': 'apply_url',       // ID mapeado
        'title': 'title',        // T√≠tulo mapeado
        'location': 'location',  // Ubicaci√≥n mapeada
        
        // Mapeos tradicionales por nombre (para compatibilidad)
        'codigo': 'apply_url',
        'titulo': 'title',
        'puesto': 'title',
        'jobtitle': 'title',
        'job_title': 'title',
        'content': 'description',
        'description': 'description',
        'descripcion': 'description',
        'company': 'company',
        'empresa': 'company',
        'company_name': 'company',
        'category': 'sector',
        'categoria': 'sector',
        'sector': 'sector',
        'address': 'location',
        'direccion': 'location',
        'ubicacion': 'location',
        'city': 'location',
        'ciudad': 'location',
        'localidad': 'location',
        'municipio': 'location',
        'region': 'location',
        'provincia': 'location',
        'comunidad': 'location',
        'country': 'location',
        'pais': 'location',
        'pa√≠s': 'location',
        'postcode': 'location',
        'codigo_postal': 'location',
        'cp': 'location',
        'postal_code': 'location',
        'url': 'apply_url',
        'enlace': 'apply_url',
        'external_url': 'apply_url',
        'url_apply': 'apply_url',
        'url_aplicacion': 'apply_url',
        'application_url': 'apply_url',
        'apply_url': 'apply_url',
        'publication': 'published_at',
        'fecha': 'published_at',
        'publication_date': 'published_at',
        'date': 'published_at',
        'fecha_publicacion': 'published_at',
        'salary': 'salary_min',
        'salario': 'salary_min',
        'salary_min': 'salary_min',
        'salario_min': 'salary_min',
        'salary_max': 'salary_max',
        'salario_max': 'salary_max',
        'jobtype': 'contract_type',
        'tipo_contrato': 'contract_type',
        'job_type': 'contract_type',
        'tipo': 'contract_type',
        'vacancies': 'contract_type',  // temporal
        'vacantes': 'contract_type',
        'num_vacancies': 'contract_type',
        'numero_vacantes': 'contract_type'
      }

      // Crear mapeos autom√°ticos
      for (const sourceField of offerFields) {
        const lowerField = sourceField.toLowerCase()
        const targetField = standardMappings[lowerField]

        if (targetField) {
          mappings.push({
            ConnectionId: this.connection.id,
            SourceField: sourceField,
            TargetField: targetField,
            TransformationType: this.detectMappingType(sourceField, sampleOffer[sourceField]),
            TransformationRule: null
          })
        }
      }

      // Guardar mapeos en la base de datos
      console.log(`üîÑ Insertando ${mappings.length} mapeos en ClientFieldMappings...`)
      for (const mapping of mappings) {
        console.log(`üìã Insertando mapeo: ${mapping.SourceField} ‚Üí ${mapping.TargetField}`)
        
        try {
          await pool
            .request()
            .input("ConnectionId", sql.Int, mapping.ConnectionId)
            .input("SourceField", sql.NVarChar(255), mapping.SourceField)
            .input("TargetField", sql.NVarChar(255), mapping.TargetField)
            .input("TransformationType", sql.NVarChar(50), mapping.TransformationType)
            .input("TransformationRule", sql.NVarChar(sql.MAX), mapping.TransformationRule)
            .query(`
              MERGE INTO ClientFieldMappings WITH (HOLDLOCK) AS Target
              USING (SELECT @ConnectionId AS ConnectionId, @SourceField AS SourceField, @TargetField AS TargetField) AS Source
              ON Target.ConnectionId = Source.ConnectionId 
              AND Target.SourceField = Source.SourceField
              AND Target.TargetField = Source.TargetField
              WHEN MATCHED THEN
                  UPDATE SET 
                      TransformationType = @TransformationType,
                      TransformationRule = @TransformationRule
              WHEN NOT MATCHED THEN
                  INSERT (ConnectionId, SourceField, TargetField, TransformationType, TransformationRule)
                  VALUES (@ConnectionId, @SourceField, @TargetField, @TransformationType, @TransformationRule);
            `)
          console.log(`‚úÖ Mapeo insertado exitosamente: ${mapping.SourceField} ‚Üí ${mapping.TargetField}`)
        } catch (insertError) {
          console.error(`‚ùå Error insertando mapeo ${mapping.SourceField} ‚Üí ${mapping.TargetField}:`, insertError.message)
        }
      }

      console.log(`‚úÖ Generated ${mappings.length} automatic mappings`)
      return mappings

    } catch (error) {
      console.error("‚ùå Error generating automatic mapping:", error)
      // No interrumpir el proceso principal
      return []
    }
  }

  // ‚úÖ DETECTAR TIPO DE MAPEO
  detectMappingType(fieldName, value) {
    const name = fieldName.toLowerCase()
    const stringValue = String(value || "")

    // URLs
    if (name.includes("url") || name.includes("link") || name.includes("enlace") || stringValue.startsWith("http")) {
      return "STRING"
    }

    // Fechas
    if (name.includes("date") || name.includes("fecha") || name.includes("publication") || name.includes("created")) {
      return "DATE"
    }

    // N√∫meros
    if (name.includes("id") || name.includes("codigo") || name.includes("count") || name.includes("number") || name.includes("salary") || name.includes("salario") || name.includes("vacancies") || name.includes("vacantes")) {
      return "NUMBER"
    }

    // Por defecto string
    return "STRING"
  }
}

module.exports = CSVProcessor